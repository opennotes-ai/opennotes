# Open Notes Docker Compose - Base Configuration
#
# This is the base Docker Compose file containing all service definitions
# in an environment-agnostic way. It should be combined with environment-specific
# override files for different deployment scenarios.
#
# Usage:
#   Development (auto-loads docker-compose.override.yml):
#     docker compose up
#
#   Development with monitoring:
#     docker compose --profile monitoring up
#
#   Production:
#     docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
#
#   Production with monitoring:
#     docker compose -f docker-compose.yml -f docker-compose.prod.yml --profile monitoring up -d
#
#   Staging (uses production config with staging env vars):
#     docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
#
#   Testing (requires dev environment down, or use different env vars for ports):
#     docker compose up --abort-on-container-exit
#
# Profiles:
#   - monitoring: Observability stack (Prometheus, Grafana, Loki, Tempo, etc.)
#
# Note: Migrations run automatically on opennotes-server startup.
#       Use SKIP_MIGRATIONS=true to disable for worker instances if needed.
#
# Note: Development API keys auto-seed on first startup in development.
#       Set SEED_DEV_API_KEYS=true in environment to enable.
#       Enabled by default in docker-compose.override.yml.
#
# Key Principles:
# - No ports exposed (override files handle that)
# - No restart policies (override files handle that)
# - No volume mounts for code (override files handle that for dev)
# - Environment variables with sensible defaults
# - Health checks defined once, used everywhere
# - Build contexts relative to this file's location
# - Profiles for optional service groups

services:
  # PostgreSQL - Relational database with pgvector extension
  # Use POSTGRES_IMAGE env var to override (e.g., for PGroonga support)
  postgres:
    image: ${POSTGRES_IMAGE:-pgvector/pgvector:pg18}
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-opennotes}
      POSTGRES_USER: ${POSTGRES_USER:-opennotes}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-testpass}
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=C"
    # PostgreSQL 18+ uses /var/lib/postgresql with subdirectory for data
    # See: https://github.com/docker-library/postgres/pull/1259
    volumes:
      - postgres_data:/var/lib/postgresql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-opennotes}"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - opennotes

  # Redis - Cache and rate limiting
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - opennotes
    command: redis-server --appendonly yes

  # NATS JetStream - Event streaming and messaging
  nats:
    image: nats:2.10-alpine
    command:
      - "--jetstream"
      - "--store_dir=/data"
      - "--http_port=8222"
    volumes:
      - nats_data:/data
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - opennotes

  # Open Notes Server - Python/FastAPI backend API
  opennotes-server:
    build:
      context: .
      dockerfile: ./opennotes-server/Dockerfile
    environment:
      # Environment configuration
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - DEBUG=${DEBUG:-false}

      # Database connection
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-opennotes}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-opennotes}

      # Cache and messaging
      - REDIS_URL=redis://redis:6379/${REDIS_DB:-0}
      - NATS_URL=nats://nats:4222

      # Server configuration
      - SERVER_HOST=${SERVER_HOST:-0.0.0.0}
      - SERVER_PORT=8000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # Authentication
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:?JWT secret key is required}

      # Encryption keys for sensitive data
      # CRITICAL: Use strong, unique keys in production!
      # Generate CREDENTIALS_ENCRYPTION_KEY: python -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())'
      # Generate ENCRYPTION_MASTER_KEY: python -c 'import secrets, base64; print(base64.urlsafe_b64encode(secrets.token_bytes(32)).decode())'
      - CREDENTIALS_ENCRYPTION_KEY=${CREDENTIALS_ENCRYPTION_KEY:-WnBxdZ2BU0Mh-jhZgVO2rRkncGmz0d54PTdyH_oaL38=}
      - ENCRYPTION_MASTER_KEY=${ENCRYPTION_MASTER_KEY:-Eh1uymAtKUglSt9gjKN_Ft96bBOnu0Y8uNxm1AoNN-Q=}

      # OpenAI API key for global fallback (used when community servers don't have their own)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}

      # Optional services
      - SCORING_ENABLED=${SCORING_ENABLED:-true}
      - WORKER_ENABLED=${WORKER_ENABLED:-true}
      - MAX_WORKERS=${MAX_WORKERS:-2}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - opennotes

  # Open Notes Discord - TypeScript/Node.js Discord bot
  opennotes-discord:
    build:
      context: .
      dockerfile: ./opennotes-discord/Dockerfile
    environment:
      # Environment configuration
      - NODE_ENV=${NODE_ENV:-production}

      # Database connection (Node.js uses different connection string format)
      - DATABASE_URL=postgresql://${POSTGRES_USER:-opennotes}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-opennotes}

      # Cache and messaging
      - REDIS_URL=redis://redis:6379
      - NATS_URL=nats://nats:4222

      # Server configuration
      - PORT=3000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # Service communication
      - OPENNOTES_SERVICE_URL=http://opennotes-server:8000
      - OPENNOTES_API_KEY=${OPENNOTES_API_KEY:-}

      # Discord credentials
      - DISCORD_TOKEN=${DISCORD_TOKEN:?Discord bot token is required}
      - DISCORD_CLIENT_ID=${DISCORD_CLIENT_ID:?Discord client ID is required}
      - DISCORD_PUBLIC_KEY=${DISCORD_PUBLIC_KEY:-}

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
      opennotes-server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - opennotes

  # Open Notes Taskiq Worker - Background task processor for ML/chunking operations
  # This service runs taskiq workers that consume tasks from NATS queue
  opennotes-worker:
    build:
      context: .
      dockerfile: ./opennotes-server/Dockerfile
    command: ["python", "-m", "taskiq", "worker", "src.tasks.broker:get_broker", "-fsd", "-tp", "**/*tasks.py"]
    environment:
      # Environment configuration
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - DEBUG=${DEBUG:-false}

      # Database connection
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-opennotes}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-opennotes}

      # Cache and messaging
      - REDIS_URL=redis://redis:6379/${REDIS_DB:-0}
      - NATS_URL=nats://nats:4222

      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ENABLE_JSON_LOGGING=${ENABLE_JSON_LOGGING:-false}

      # Authentication (needed for database access)
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:?JWT secret key is required}
      - CREDENTIALS_ENCRYPTION_KEY=${CREDENTIALS_ENCRYPTION_KEY:-WnBxdZ2BU0Mh-jhZgVO2rRkncGmz0d54PTdyH_oaL38=}
      - ENCRYPTION_MASTER_KEY=${ENCRYPTION_MASTER_KEY:-Eh1uymAtKUglSt9gjKN_Ft96bBOnu0Y8uNxm1AoNN-Q=}

      # OpenAI for rechunking tasks
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
    networks:
      - opennotes

  # Open Notes Audit Worker - Background worker for async audit log processing
  opennotes-audit-worker:
    build:
      context: .
      dockerfile: ./opennotes-server/Dockerfile
    command: ["uv", "run", "python", "scripts/run_audit_worker.py"]
    environment:
      # Environment configuration
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - DEBUG=${DEBUG:-false}

      # Database connection
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-opennotes}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-opennotes}

      # Cache and messaging
      - REDIS_URL=redis://redis:6379/${REDIS_DB:-0}
      - NATS_URL=nats://nats:4222

      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ENABLE_JSON_LOGGING=${ENABLE_JSON_LOGGING:-true}

      # Authentication (needed for decryption if worker handles encrypted data)
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:?JWT secret key is required}
      - CREDENTIALS_ENCRYPTION_KEY=${CREDENTIALS_ENCRYPTION_KEY:-WnBxdZ2BU0Mh-jhZgVO2rRkncGmz0d54PTdyH_oaL38=}
      - ENCRYPTION_MASTER_KEY=${ENCRYPTION_MASTER_KEY:-Eh1uymAtKUglSt9gjKN_Ft96bBOnu0Y8uNxm1AoNN-Q=}

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
    networks:
      - opennotes

  # Monitoring Stack (enabled with --profile monitoring)
  # Prometheus - Metrics collection and storage
  prometheus:
    image: prom/prometheus:v2.48.0
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=30d'
    volumes:
      # TODO: Add prometheus config if monitoring profile is needed
      - prometheus_data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - opennotes
      - monitoring
    profiles:
      - monitoring

  # Grafana - Metrics visualization and dashboards
  grafana:
    image: grafana/grafana:10.2.2
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=redis-datasource
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL:-http://localhost:3001}
    volumes:
      # TODO: Add grafana provisioning if monitoring profile is needed
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - monitoring
    profiles:
      - monitoring

  # Loki - Log aggregation
  loki:
    image: grafana/loki:2.9.3
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      # TODO: Add loki config if monitoring profile is needed
      - loki_data:/loki
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - monitoring
    profiles:
      - monitoring

  # Promtail - Log collection agent
  promtail:
    image: grafana/promtail:2.9.3
    command: -config.file=/etc/promtail/config.yml
    volumes:
      # TODO: Add promtail config if monitoring profile is needed
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    depends_on:
      - loki
    networks:
      - monitoring
    profiles:
      - monitoring

  # Tempo - Distributed tracing
  tempo:
    image: grafana/tempo:2.3.1
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      # TODO: Add tempo config if monitoring profile is needed
      - tempo_data:/tmp/tempo
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3200/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - monitoring
      - opennotes
    profiles:
      - monitoring

  # Alertmanager - Alert routing and management
  alertmanager:
    image: prom/alertmanager:v0.26.0
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    volumes:
      # TODO: Add alertmanager config if monitoring profile is needed
      - alertmanager_data:/alertmanager
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - monitoring
    profiles:
      - monitoring

  # Node Exporter - Host system metrics
  node-exporter:
    image: prom/node-exporter:v1.7.0
    command:
      - '--path.rootfs=/host'
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - monitoring
    profiles:
      - monitoring

  # cAdvisor - Container metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    privileged: true
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    networks:
      - monitoring
    profiles:
      - monitoring

networks:
  opennotes:
    driver: bridge
  monitoring:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  nats_data:
  prometheus_data:
  grafana_data:
  loki_data:
  tempo_data:
  alertmanager_data:
